{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent IDs for each lender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# banks\n",
    "USBank= 504713  # US Bank\n",
    "Wells=451965  #Wells Fargo\n",
    "Bell=19581    # Bell Bank\n",
    "\n",
    "# online lenders\n",
    "Quicken=7197000003        #Quicken Loan\n",
    "AMEC=411941324             #American Mortgage & Equity Consultants Inc.\n",
    "Guaranteed=364327855      # Guaranteed Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegress(X_train, y_train,X_test,y_test):\n",
    "#####################################\n",
    "# use Logistic Regression to train and test a model\n",
    "# returning test score\n",
    "\n",
    "    # create model\n",
    "    LRmodel = LogisticRegression()\n",
    "    # fit model with training data\n",
    "#     print(\"X-train\",X_train.head())\n",
    "#     print(\"y_train\",y_train.head())\n",
    "    LRmodel.fit(X_train, y_train)\n",
    "\n",
    "       # confusion matrix \n",
    "    y_pred=LRmodel.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(\"confusion matrix\")\n",
    "    print(cnf_matrix)\n",
    "    \n",
    "    # validate the model using testing data\n",
    "    test_score=LRmodel.score(X_test, y_test)\n",
    "    params=LRmodel.get_params(deep=False)\n",
    "#    print(\"test_score\",test_score)\n",
    "#    print(\"params=\",params)\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignData(set, data_df):\n",
    "##############################################\n",
    "# choose the lender group for test\n",
    "# set = 0 use all of data_df this is all lenders\n",
    "# set = 1 select from data_df for 'respondent id' in Banks\n",
    "# set = 2 select from data_df for 'respondent id' in Online\n",
    "# set > 3 select from data_df for 'respondent id' = set\n",
    "# split for train and test data\n",
    "# call LogRegress\n",
    "\n",
    "    #reduce the data used for set > 0 to a subset of lenders or a particular lender\n",
    "    if set > 3 :\n",
    "        data_df=data_df.loc[data_df['respondent id'] == set,:]\n",
    "    elif set == 2:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == Quicken) | (data_df['respondent id'] == AMEC) | (data_df['respondent id'] == Guaranteed), :]\n",
    "    elif set == 1:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == USBank) | (data_df['respondent id'] == Wells) | (data_df['respondent id'] == Bell), :]\n",
    "           \n",
    "        # Assign X (data) and y (target)\n",
    "    X=data_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y=data_df[\"action modified\"]\n",
    "#    print(\"shape\", X.shape, y.shape)  , stratify=y\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    return LogRegress(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignData2(set, data_df,test_df):\n",
    "##############################################\n",
    "# FOR USE WHEN TRAINING AND TESTING ON DIFFERENT SETS\n",
    "# choose the lender group for BOTH train and test data\n",
    "# set = 0 use all of data_df this is all lenders\n",
    "# set = 1 select from data_df for 'respondent id' in Banks\n",
    "# set = 2 select from data_df for 'respondent id' in Online\n",
    "# set > 3 select from data_df for 'respondent id' = set\n",
    "# call LogRegress\n",
    "\n",
    "\n",
    "    #reduce the data used for set > 0 to a subset of lenders or a particular lender\n",
    "    if set > 3 :\n",
    "        data_df=data_df.loc[data_df['respondent id'] == set,:]\n",
    "        test_df=test_df.loc[test_df['respondent id'] == set,:]\n",
    "    elif set == 2:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == Quicken) | (data_df['respondent id'] == AMEC) | (data_df['respondent id'] == Guaranteed), :]\n",
    "        test_df=test_df.loc[(test_df['respondent id'] == Quicken) | (test_df['respondent id'] == AMEC) | (test_df['respondent id'] == Guaranteed), :]\n",
    "    elif set == 1:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == USBank) | (data_df['respondent id'] == Wells) | (data_df['respondent id'] == Bell), :]\n",
    "        test_df=test_df.loc[(test_df['respondent id'] == USBank) | (test_df['respondent id'] == Wells) | (test_df['respondent id'] == Bell), :]\n",
    "           \n",
    "        # Assign X (data) and y (target) for training\n",
    "    X_train=data_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y_train=data_df[\"action modified\"]\n",
    "    \n",
    "            # Assign X (data) and y (target) for test\n",
    "    X_test=test_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y_test=test_df[\"action modified\"]\n",
    "#    print(\"shape\", X.shape, y.shape)\n",
    "\n",
    "\n",
    "    return LogRegress(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenderTest(test_data):\n",
    "#################################################\n",
    "# goes through the 9 tests of lender groups with one version of the test data\n",
    "# 0- All data\n",
    "# 1- all banks\n",
    "# 2- all online lenders\n",
    "# 3 USBANK 4- Wells 5- Bell \n",
    "# 6- Quicken 7- AMEC 8- Guaranteed\n",
    "# returns the results in list\n",
    "############################################################\n",
    "    result_list=[]\n",
    "    # get result for all data\n",
    "    result_list.append(AssignData(0,test_data))\n",
    "    # get result for all banks\n",
    "    result_list.append(AssignData(1,test_data))\n",
    "    #result for all online\n",
    "    result_list.append(AssignData(2,test_data))\n",
    "    # result for USBank, Wells, Bell \n",
    "    result_list.append(AssignData(USBank,test_data))\n",
    "    result_list.append(AssignData(Wells,test_data))\n",
    "    result_list.append(AssignData(Bell,test_data))\n",
    "    #result for Quicken, AMEC, Guaranteed\n",
    "    result_list.append(AssignData(Quicken,test_data))\n",
    "    result_list.append(AssignData(AMEC,test_data))\n",
    "    result_list.append(AssignData(Guaranteed,test_data))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenderTest2(train_data,test_data):\n",
    "#################################################\n",
    "# FOR USE WHEN TRAINING AND TESTING ON DIFFERENT SETS\n",
    "# goes through the 9 tests  with one version of the test data\n",
    "# 0- All data\n",
    "# 1- all banks\n",
    "# 2- all online lenders\n",
    "# 3 USBANK 4- Wells 5- Bell \n",
    "# 6- Quicken 7- AMEC 8- Guaranteed\n",
    "# returns the results in list\n",
    "############################################################\n",
    "    result_list=[]\n",
    "    # get result for all data\n",
    "    result_list.append(AssignData2(0,train_data,test_data))\n",
    "    # get result for all banks\n",
    "    result_list.append(AssignData2(1,train_data,test_data))\n",
    "    #result for all online\n",
    "    result_list.append(AssignData2(2,train_data,test_data))\n",
    "    # result for USBank, Wells, Bell \n",
    "    result_list.append(AssignData2(USBank,train_data,test_data))\n",
    "    result_list.append(AssignData2(Wells,train_data,test_data))\n",
    "    result_list.append(AssignData2(Bell,train_data,test_data))\n",
    "    #result for Quicken, AMEC, Guaranteed\n",
    "    result_list.append(AssignData2(Quicken,train_data,test_data))\n",
    "    result_list.append(AssignData2(AMEC,train_data,test_data))\n",
    "    result_list.append(AssignData2(Guaranteed,train_data,test_data))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main body of code \n",
    "read in data file\n",
    "\n",
    "prepare training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"AllData2017.csv\"\n",
    "loan_data=pd.read_csv(file)\n",
    "\n",
    "loan_data=loan_data[[\"respondent id\",\"agency code\",\"property type\",\"loan purpose\",\"loan amount\",\"county\",\\\n",
    "                     \"applicant race 1\",\"sex\", \"hoepa status\",\"lien status\",\"loan type modified\",\\\n",
    "                     \"action modified\",\"income cleaned\",\"income loan ratio\"]]\n",
    "\n",
    "sexless_data=loan_data.drop([\"sex\"], axis=1)\n",
    "raceless_data=loan_data.drop([\"applicant race 1\"], axis=1)\n",
    "loantypeless_data=loan_data.drop([\"loan type modified\"], axis=1) \n",
    "incomeratioless_data=loan_data.drop([\"income loan ratio\"], axis=1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare unique group test data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single gender  - genderless data\n",
    "female_data=loan_data[loan_data[\"sex\"] == 2]\n",
    "female_data=female_data.drop([\"sex\"],axis=1)\n",
    "male_data=loan_data[loan_data[\"sex\"] == 1]\n",
    "male_data=male_data.drop([\"sex\"],axis=1)\n",
    "\n",
    "#single race - raceless data\n",
    "indian_data=loan_data[loan_data[\"applicant race 1\"] == 1]\n",
    "indian_data=indian_data.drop([\"applicant race 1\"],axis=1)\n",
    "asian_data=loan_data[loan_data[\"applicant race 1\"] == 2]\n",
    "asian_data=asian_data.drop([\"applicant race 1\"],axis=1)\n",
    "black_data=loan_data[loan_data[\"applicant race 1\"] == 3]\n",
    "black_data=black_data.drop([\"applicant race 1\"],axis=1)\n",
    "hawaii_data=loan_data[loan_data[\"applicant race 1\"] == 4]\n",
    "hawaii_data=hawaii_data.drop([\"applicant race 1\"],axis=1)\n",
    "white_data=loan_data[loan_data[\"applicant race 1\"] == 5]\n",
    "white_data=white_data.drop([\"applicant race 1\"],axis=1)\n",
    "\n",
    "# single loan type - loantypeless data\n",
    "govtbacked_data=loan_data[loan_data[\"loan type modified\"] == 0]\n",
    "govtbacked_data=govtbacked_data.drop([\"loan type modified\"],axis=1)\n",
    "conventional_data=loan_data[loan_data[\"loan type modified\"] == 1]\n",
    "conventional_data=conventional_data.drop([\"loan type modified\"],axis=1)\n",
    "\n",
    "# single income ratio group - income ratio less data  (income ratio = (income / loan amount) * 100 )\n",
    "lowincomeratio_data=loan_data[loan_data[\"income loan ratio\"] <= 100]\n",
    "lowincomeratio_data=lowincomeratio_data.drop([\"income loan ratio\"],axis=1)\n",
    "medincomeratio_data=loan_data[(loan_data[\"income loan ratio\"] > 100) & (loan_data[\"income loan ratio\"] < 200) ]\n",
    "medincomeratio_data=medincomeratio_data.drop([\"income loan ratio\"],axis=1)\n",
    "highincomeratio_data=loan_data[loan_data[\"income loan ratio\"] >= 200]\n",
    "highincomeratio_data=highincomeratio_data.drop([\"income loan ratio\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tests and append lender sets to dataframe\n",
    "for each training group run with same train and test data\n",
    "\n",
    "next run with training data and unique group test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[ 110 1930]\n",
      " [  60 9908]]\n",
      "confusion matrix\n",
      "[[ 151 1248]\n",
      " [  64 6780]]\n",
      "confusion matrix\n",
      "[[   0  606]\n",
      " [   0 3159]]\n",
      "confusion matrix\n",
      "[[  97  538]\n",
      " [  96 1943]]\n",
      "confusion matrix\n",
      "[[  70  631]\n",
      " [  22 3026]]\n",
      "confusion matrix\n",
      "[[   0   44]\n",
      " [   0 1777]]\n",
      "confusion matrix\n",
      "[[   0  565]\n",
      " [   0 1531]]\n",
      "confusion matrix\n",
      "[[   0   52]\n",
      " [   0 1287]]\n",
      "confusion matrix\n",
      "[[  2  17]\n",
      " [  0 312]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_fields</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.834277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banks</th>\n",
       "      <td>0.840835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online</th>\n",
       "      <td>0.839044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usbank</th>\n",
       "      <td>0.762902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wells</th>\n",
       "      <td>0.825820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bell</th>\n",
       "      <td>0.975837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quicken</th>\n",
       "      <td>0.730439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amec</th>\n",
       "      <td>0.961165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.948640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            all_fields\n",
       "all           0.834277\n",
       "banks         0.840835\n",
       "online        0.839044\n",
       "usbank        0.762902\n",
       "wells         0.825820\n",
       "bell          0.975837\n",
       "quicken       0.730439\n",
       "amec          0.961165\n",
       "guaranteed    0.948640"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df=pd.DataFrame(index=[\"all\",\"banks\",\"online\",\"usbank\",\"wells\",\"bell\",\"quicken\",\"amec\",\"guaranteed\"])\n",
    "\n",
    "result_df[\"all_fields\"]=LenderTest(loan_data)\n",
    "\n",
    "# #results for the effectof gender \n",
    "# result_df[\"sexless\"]=LenderTest(sexless_data)\n",
    "# result_df[\"female\"]=LenderTest2(sexless_data,female_data)\n",
    "# result_df[\"male\"]=LenderTest2(sexless_data,male_data)\n",
    "\n",
    "# #results for the effect of race\n",
    "# result_df[\"raceless\"]=LenderTest(raceless_data)\n",
    "# result_df[\"indian\"]=LenderTest2(raceless_data,indian_data)\n",
    "# result_df[\"asian\"]=LenderTest2(raceless_data,asian_data)\n",
    "# result_df[\"black\"]=LenderTest2(raceless_data,black_data)\n",
    "# result_df[\"hawaiian\"]=LenderTest2(raceless_data,hawaii_data)\n",
    "# result_df[\"white\"]=LenderTest2(raceless_data,white_data)\n",
    "\n",
    "# #results for the effect of loan type\n",
    "# result_df[\"loantypeless\"]=LenderTest(loantypeless_data)\n",
    "# result_df[\"govtbacked\"]=LenderTest2(loantypeless_data,govtbacked_data)\n",
    "# result_df[\"conventional\"]=LenderTest2(loantypeless_data,conventional_data)\n",
    "\n",
    "# # results for the effect of income / loan ratio \n",
    "# result_df[\"incomeratioless\"]=LenderTest(incomeratioless_data)\n",
    "# result_df[\"low income ratio\"]=LenderTest2(incomeratioless_data,lowincomeratio_data)\n",
    "# result_df[\"med income ratio\"]=LenderTest2(incomeratioless_data,medincomeratio_data)\n",
    "# result_df[\"high income ratio\"]=LenderTest2(incomeratioless_data,highincomeratio_data)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
