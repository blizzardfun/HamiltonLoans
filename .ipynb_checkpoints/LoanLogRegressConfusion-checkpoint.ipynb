{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "respondent IDs for each lender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# banks\n",
    "USBank= 504713  # US Bank\n",
    "Wells=451965  #Wells Fargo\n",
    "Bell=19581    # Bell Bank\n",
    "\n",
    "# online lenders\n",
    "Quicken=7197000003        #Quicken Loan\n",
    "AMEC=411941324             #American Mortgage & Equity Consultants Inc.\n",
    "Guaranteed=364327855      # Guaranteed Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfusionSpread (cnf_matrix):\n",
    "    print(\"confusion matrix\")\n",
    "    print(cnf_matrix)\n",
    "    cnf_list=[cnf_matrix[0][0],cnf_matrix[0][1],cnf_matrix[1][0],cnf_matrix[1][1]]\n",
    "    return cnf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegress(X_train, y_train,X_test,y_test):\n",
    "#####################################\n",
    "# use Logistic Regression to train and test a model\n",
    "# returning test score\n",
    "\n",
    "    # create model\n",
    "    LRmodel = LogisticRegression()\n",
    "    # fit model with training data\n",
    "#     print(\"X-train\",X_train.head())\n",
    "#     print(\"y_train\",y_train.head())\n",
    "    LRmodel.fit(X_train, y_train)\n",
    "\n",
    "       # confusion matrix \n",
    "    y_pred=LRmodel.predict(X_test)\n",
    "    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cnf_result=ConfusionSpread(cnf_matrix)\n",
    "    \n",
    "    # validate the model using testing data\n",
    "    test_score=LRmodel.score(X_test, y_test)\n",
    "#    params=LRmodel.get_params(deep=False)\n",
    "#    print(\"test_score\",test_score)\n",
    "#    print(\"params=\",params)\n",
    "    return cnf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignData(set, data_df):\n",
    "##############################################\n",
    "# choose the lender group for test\n",
    "# set = 0 use all of data_df this is all lenders\n",
    "# set = 1 select from data_df for 'respondent id' in usbank, wells, quicken\n",
    "# set > 2 select from data_df for 'respondent id' = set\n",
    "# split for train and test data\n",
    "# call LogRegress\n",
    "\n",
    "    #reduce the data used for set > 0 to a subset of lenders or a particular lender\n",
    "    if set > 2 :\n",
    "        data_df=data_df.loc[data_df['respondent id'] == set,:]\n",
    "    elif set == 1:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == USBank) | (data_df['respondent id'] == Wells) | (data_df['respondent id'] == Quicken), :]\n",
    "           \n",
    "        # Assign X (data) and y (target)\n",
    "    X=data_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y=data_df[\"action modified\"]\n",
    "#    print(\"shape\", X.shape, y.shape)  , stratify=y\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    return LogRegress(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignData2(set, data_df,test_df):\n",
    "##############################################\n",
    "# FOR USE WHEN TRAINING AND TESTING ON DIFFERENT SETS\n",
    "# choose the lender group for BOTH train and test data\n",
    "# set = 0 use all of data_df this is all lenders\n",
    "# set = 1 select from data_df for 'respondent id' in usbank, wells quicken\n",
    "# set > 2 select from data_df for 'respondent id' = set\n",
    "# call LogRegress\n",
    "\n",
    "\n",
    "    #reduce the data used for set > 0 to a subset of lenders or a particular lender\n",
    "    if set > 2 :\n",
    "        data_df=data_df.loc[data_df['respondent id'] == set,:]\n",
    "        test_df=test_df.loc[test_df['respondent id'] == set,:]\n",
    "    elif set == 1:\n",
    "        data_df=data_df.loc[(data_df['respondent id'] == USBank) | (data_df['respondent id'] == Wells) | (data_df['respondent id'] == Quicken), :]\n",
    "        test_df=test_df.loc[(test_df['respondent id'] == USBank) | (test_df['respondent id'] == Wells) | (test_df['respondent id'] == Quicken), :]\n",
    "           \n",
    "        # Assign X (data) and y (target) for training\n",
    "    X_train=data_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y_train=data_df[\"action modified\"]\n",
    "    \n",
    "            # Assign X (data) and y (target) for test\n",
    "    X_test=test_df.drop([\"action modified\",\"respondent id\"],axis=1)\n",
    "    y_test=test_df[\"action modified\"]\n",
    "#    print(\"shape\", X.shape, y.shape)\n",
    "\n",
    "\n",
    "    return LogRegress(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenderTest(test_data,testname):\n",
    "#################################################\n",
    "# goes through the 4 tests of lender groups with one version of the test data\n",
    "# all 3 usbank, wells, quicken\n",
    "#  USBANK \n",
    "# Wells \n",
    "# Quicken\n",
    "# returns the results in list\n",
    "############################################################\n",
    "\n",
    "    # for returning confusion matrix\n",
    "    result_dict={}\n",
    "    # get result for all 3\n",
    "    result_dict['all'+ testname]=AssignData(1,test_data)\n",
    "    # result for USBank \n",
    "    result_dict['usbank'+ testname]=AssignData(USBank,test_data)\n",
    "        # result for Wells\n",
    "    result_dict['wells'+ testname]=AssignData(Wells,test_data)\n",
    "    #result for Quicken\n",
    "    result_dict['quicken'+ testname]=AssignData(Quicken,test_data)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LenderTest2(train_data,test_data,testname):\n",
    "#################################################\n",
    "# goes through the 4 tests of lender groups with one version of the test data\n",
    "# all 3 usbank, wells, quicken\n",
    "#  USBANK \n",
    "# Wells \n",
    "# Quicken\n",
    "# returns the results in list\n",
    "############################################################\n",
    "\n",
    "# for returning confusion matirx\n",
    "    result_dict={}\n",
    "    # get result for all 3\n",
    "    result_dict['all'+ testname]=AssignData2(1,train_data,test_data)\n",
    "    # result for USBank, \n",
    "    result_dict['usbank'+ testname]=AssignData2(USBank,train_data,test_data)\n",
    "        # result for Wells\n",
    "    result_dict['wells'+ testname]=AssignData2(Wells,train_data,test_data)\n",
    "    #result for Quicken\n",
    "    result_dict['quicken'+ testname]=AssignData2(Quicken,train_data,test_data)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main body of code \n",
    "read in data file\n",
    "\n",
    "prepare training data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"AllData2017.csv\"\n",
    "loan_data=pd.read_csv(file)\n",
    "\n",
    "loan_data=loan_data[[\"respondent id\",\"agency code\",\"property type\",\"loan purpose\",\"loan amount\",\\\n",
    "                     \"applicant race 1\",\"sex\",\"lien status\",\"loan type modified\",\\\n",
    "                     \"action modified\",\"income cleaned\",\"income loan ratio\"]]\n",
    "\n",
    "race_sex_less_data=loan_data.drop([\"sex\",\"applicant race 1\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare unique group test data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single gender  - genderless data\n",
    "female_data=loan_data[loan_data[\"sex\"] == 2]\n",
    "female_data=female_data.drop([\"sex\",\"applicant race 1\"],axis=1)\n",
    "male_data=loan_data[loan_data[\"sex\"] == 1]\n",
    "male_data=male_data.drop([\"sex\",\"applicant race 1\"],axis=1)\n",
    "\n",
    "#single race - raceless data\n",
    "asian_data=loan_data[loan_data[\"applicant race 1\"] == 2]\n",
    "asian_data=asian_data.drop([\"sex\",\"applicant race 1\"],axis=1)\n",
    "\n",
    "black_data=loan_data[loan_data[\"applicant race 1\"] == 3]\n",
    "black_data=black_data.drop([\"sex\",\"applicant race 1\"],axis=1)\n",
    "\n",
    "white_data=loan_data[loan_data[\"applicant race 1\"] == 5]\n",
    "white_data=white_data.drop([\"sex\",\"applicant race 1\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run tests and concat lender sets to dataframe\n",
    "run for 3 lenders, as a group and individually\n",
    "\n",
    "all data - train and test with same data\n",
    "\n",
    "raceless and sexless (blind) data - train and test same data\n",
    "\n",
    "asian -train with blind training data , test with unique group test data\n",
    "\n",
    "black -train with blind training data , test with unique group test data \n",
    "\n",
    "white -train with blind training data , test with unique group test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[ 112 1839]\n",
      " [  54 6513]]\n",
      "confusion matrix\n",
      "[[  95  540]\n",
      " [  91 1948]]\n",
      "confusion matrix\n",
      "[[  69  632]\n",
      " [  22 3026]]\n",
      "confusion matrix\n",
      "[[   0  565]\n",
      " [   0 1531]]\n",
      "confusion matrix\n",
      "[[  71 1880]\n",
      " [  28 6539]]\n",
      "confusion matrix\n",
      "[[  99  536]\n",
      " [ 110 1929]]\n",
      "confusion matrix\n",
      "[[  55  646]\n",
      " [  16 3032]]\n",
      "confusion matrix\n",
      "[[   0  565]\n",
      " [   0 1531]]\n",
      "confusion matrix\n",
      "[[ 110 2254]\n",
      " [  41 7537]]\n",
      "confusion matrix\n",
      "[[ 184  720]\n",
      " [ 135 2307]]\n",
      "confusion matrix\n",
      "[[  95  880]\n",
      " [  29 3620]]\n",
      "confusion matrix\n",
      "[[   0  485]\n",
      " [   0 1487]]\n",
      "confusion matrix\n",
      "[[  151  4001]\n",
      " [   69 15718]]\n",
      "confusion matrix\n",
      "[[ 195 1242]\n",
      " [ 178 4868]]\n",
      "confusion matrix\n",
      "[[ 138 1539]\n",
      " [  39 7848]]\n",
      "confusion matrix\n",
      "[[   0 1038]\n",
      " [   0 2854]]\n",
      "confusion matrix\n",
      "[[ 18 288]\n",
      " [  2 927]]\n",
      "confusion matrix\n",
      "[[ 21 107]\n",
      " [  8 329]]\n",
      "confusion matrix\n",
      "[[ 19 124]\n",
      " [  3 493]]\n",
      "confusion matrix\n",
      "[[ 0 35]\n",
      " [ 0 96]]\n",
      "confusion matrix\n",
      "[[ 17 310]\n",
      " [  4 571]]\n",
      "confusion matrix\n",
      "[[ 32  99]\n",
      " [ 16 151]]\n",
      "confusion matrix\n",
      "[[ 15 138]\n",
      " [  4 307]]\n",
      "confusion matrix\n",
      "[[ 0 43]\n",
      " [ 0 97]]\n",
      "confusion matrix\n",
      "[[  212  5291]\n",
      " [  101 20861]]\n",
      "confusion matrix\n",
      "[[ 311 1678]\n",
      " [ 284 6611]]\n",
      "confusion matrix\n",
      "[[  186  2087]\n",
      " [   59 10511]]\n",
      "confusion matrix\n",
      "[[   0 1241]\n",
      " [   0 3497]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_test</th>\n",
       "      <th>usbank_test</th>\n",
       "      <th>wells_test</th>\n",
       "      <th>quicken_test</th>\n",
       "      <th>all_blindtest</th>\n",
       "      <th>usbank_blindtest</th>\n",
       "      <th>wells_blindtest</th>\n",
       "      <th>quicken_blindtest</th>\n",
       "      <th>all_female</th>\n",
       "      <th>usbank_female</th>\n",
       "      <th>...</th>\n",
       "      <th>wells_asian</th>\n",
       "      <th>quicken_asian</th>\n",
       "      <th>all_black</th>\n",
       "      <th>usbank_black</th>\n",
       "      <th>wells_black</th>\n",
       "      <th>quicken_black</th>\n",
       "      <th>all_white</th>\n",
       "      <th>usbank_white</th>\n",
       "      <th>wells_white</th>\n",
       "      <th>quicken_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true-</th>\n",
       "      <td>112</td>\n",
       "      <td>95</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>99</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>311</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false-</th>\n",
       "      <td>1839</td>\n",
       "      <td>540</td>\n",
       "      <td>632</td>\n",
       "      <td>565</td>\n",
       "      <td>1880</td>\n",
       "      <td>536</td>\n",
       "      <td>646</td>\n",
       "      <td>565</td>\n",
       "      <td>2254</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>35</td>\n",
       "      <td>310</td>\n",
       "      <td>99</td>\n",
       "      <td>138</td>\n",
       "      <td>43</td>\n",
       "      <td>5291</td>\n",
       "      <td>1678</td>\n",
       "      <td>2087</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false+</th>\n",
       "      <td>54</td>\n",
       "      <td>91</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>110</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>284</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true+</th>\n",
       "      <td>6513</td>\n",
       "      <td>1948</td>\n",
       "      <td>3026</td>\n",
       "      <td>1531</td>\n",
       "      <td>6539</td>\n",
       "      <td>1929</td>\n",
       "      <td>3032</td>\n",
       "      <td>1531</td>\n",
       "      <td>7537</td>\n",
       "      <td>2307</td>\n",
       "      <td>...</td>\n",
       "      <td>493</td>\n",
       "      <td>96</td>\n",
       "      <td>571</td>\n",
       "      <td>151</td>\n",
       "      <td>307</td>\n",
       "      <td>97</td>\n",
       "      <td>20861</td>\n",
       "      <td>6611</td>\n",
       "      <td>10511</td>\n",
       "      <td>3497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        all_test  usbank_test  wells_test  quicken_test  all_blindtest  \\\n",
       "true-        112           95          69             0             71   \n",
       "false-      1839          540         632           565           1880   \n",
       "false+        54           91          22             0             28   \n",
       "true+       6513         1948        3026          1531           6539   \n",
       "\n",
       "        usbank_blindtest  wells_blindtest  quicken_blindtest  all_female  \\\n",
       "true-                 99               55                  0         110   \n",
       "false-               536              646                565        2254   \n",
       "false+               110               16                  0          41   \n",
       "true+               1929             3032               1531        7537   \n",
       "\n",
       "        usbank_female      ...        wells_asian  quicken_asian  all_black  \\\n",
       "true-             184      ...                 19              0         17   \n",
       "false-            720      ...                124             35        310   \n",
       "false+            135      ...                  3              0          4   \n",
       "true+            2307      ...                493             96        571   \n",
       "\n",
       "        usbank_black  wells_black  quicken_black  all_white  usbank_white  \\\n",
       "true-             32           15              0        212           311   \n",
       "false-            99          138             43       5291          1678   \n",
       "false+            16            4              0        101           284   \n",
       "true+            151          307             97      20861          6611   \n",
       "\n",
       "        wells_white  quicken_white  \n",
       "true-           186              0  \n",
       "false-         2087           1241  \n",
       "false+           59              0  \n",
       "true+         10511           3497  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #race gender included\n",
    "result_df=pd.DataFrame(LenderTest(loan_data,'_test'), index=['true-','false-','false+','true+'])\n",
    "    #blind test norace or gender\n",
    "confusion_df=pd.DataFrame(LenderTest(race_sex_less_data,'_blindtest'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "    # results for the effectof gender -female\n",
    "confusion_df=pd.DataFrame(LenderTest2(race_sex_less_data,female_data,'_female'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "    # results for the effectof gender -Male\n",
    "confusion_df=pd.DataFrame(LenderTest2(race_sex_less_data,male_data,'_male'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "\n",
    "#results for the effect of race asian\n",
    "confusion_df=pd.DataFrame(LenderTest2(race_sex_less_data,asian_data,'_asian'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "# #results for the effect of race black\n",
    "confusion_df=pd.DataFrame(LenderTest2(race_sex_less_data,black_data,'_black'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "# #results for the effect of race white\n",
    "confusion_df=pd.DataFrame(LenderTest2(race_sex_less_data,white_data,'_white'), index=['true-','false-','false+','true+'])\n",
    "result_df=pd.concat([result_df, confusion_df],axis=1)\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('confusionLogregress.csv', index=True,header=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
